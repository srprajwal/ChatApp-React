# -*- coding: utf-8 -*-
"""Deepfake.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iBP-LItEd-C-kDh5mY54l2iIusvCA8zg
"""

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import LSTM, Dense, GlobalAveragePooling2D, TimeDistributed
from tensorflow.keras.optimizers import Adam
import cv2
import numpy as np

# Load pre-trained ResNet50 without top layers
base_cnn = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
cnn_out = GlobalAveragePooling2D()(base_cnn.output)
cnn_model = Model(inputs=base_cnn.input, outputs=cnn_out)

# Freeze the CNN layers to retain pre-trained features
for layer in cnn_model.layers:
    layer.trainable = False

# LSTM model for sequence analysis
model = Sequential()

# CNN applied across time-distributed frames
model.add(TimeDistributed(cnn_model, input_shape=(30, 224, 224, 3)))  # 30 frames per video
model.add(LSTM(64, return_sequences=False))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))  # Binary classification (real or fake)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Display the model summary
model.summary()
# Modify frame extraction to use 10 frames instead of 30 for faster inference
def extract_frames(video_path, frame_count=10):
    video = cv2.VideoCapture(video_path)
    frames = []
    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    step = max(total_frames // frame_count, 1)

    for i in range(0, total_frames, step):
        video.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = video.read()
        if ret:
            frame = cv2.resize(frame, (224, 224))
            frames.append(frame)

        if len(frames) == frame_count:
            break

    video.release()
    return np.array(frames) / 255.0  # Normalize

# Example of loading a video and predicting with fewer frames
video_path = '/content/WhatsApp Video 2024-10-01 at 1.12.25 AM.mp4'
video_frames = extract_frames(video_path, frame_count=10)  # Use fewer frames
video_frames = np.expand_dims(video_frames, axis=0)  # Expand dimensions for batch

# Predict if the video is a deepfake or real
prediction = model.predict(video_frames)
if prediction > 0.5:
    print("Deepfake detected!")
else:
    print("Real video!")